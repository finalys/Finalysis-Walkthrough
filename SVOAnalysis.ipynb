{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf8543ea-f0d5-4bd7-9a1f-307e0db5f41c",
   "metadata": {},
   "source": [
    "## Importing the libraries, functions and cardhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6347a444-04ca-4d9d-b1b8-ea9e8adb56ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the libraries\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import xlsxwriter\n",
    "\n",
    "## Import hashfiles of card\n",
    "cardhash_df = pd.read_excel(\"SVCardInfo.xlsx\", sheet_name=\"FileData\")\n",
    "cardhash_dict = cardhash_df.set_index(\"hash\")[\"base_card_name\"].to_dict()\n",
    "\n",
    "## Import function\n",
    "from DeckClassify import DeckSearch\n",
    "from SVExcelFormatter import DeckBreakdownToExcel, SVOExcelFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2a693-e7b7-4252-9c10-891844a8e55b",
   "metadata": {},
   "source": [
    "## Importing SVO decklist file, and extracting player information from Battlefy\n",
    "- The objective is to merge data from different sources into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "762ff62a-0828-46d6-82f8-fb41ba68b73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert excel of decklinks into DataFrame\n",
    "## Input columns: Name\tPlayer ID\tDeck 1\tDeck 2\tDeck 3\n",
    "rawdf_1 = pd.read_excel('input/SVO_SEAO_Apr2023.xlsx')\n",
    "\n",
    "## Data Cleaning - Invalid decks pulled from client\n",
    "rawdf_1 = rawdf_1.loc[(rawdf_1['Deck 1'].str.len() >= 287) | (rawdf_1['Deck 2'].str.len() >= 287) | (rawdf_1['Deck 3'].str.len() >= 287)].copy().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38aea075-fd58-479a-9f7d-bcd2c0fcf2e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Extract participant and match info from Battlefy\n",
    "bfyTourCode = '6430cbc4fc426841771e5894'\n",
    "\n",
    "## Pull from battlefy and check against participating players\n",
    "targetStandings = f'https://dtmwra1jsgyb0.cloudfront.net/stages/{bfyTourCode}/latest-round-standings'\n",
    "jsonResponse = requests.get(targetStandings).json()\n",
    "df = pd.json_normalize(jsonResponse)\n",
    "\n",
    "# Extract customFields\n",
    "## Sort customFields list of dictionary by unique _id for each customFields.\n",
    "df['team.customFields'] = df['team.customFields'].apply(lambda x: sorted(x, key = lambda y: y['_id']))\n",
    "    ## Check for the number of dictionary in list before running, adjust range(0, n) accordingly.\n",
    "for n in range(0,3): \n",
    "    df[f'customField{n}'] = df['team.customFields'].apply(lambda x: x[n]['value'])\n",
    "df = df.copy()[['teamID', 'wins', 'customField0', 'customField1', 'customField2', 'team.customFields']]\n",
    "df = df.rename(columns = {\"wins\": \"Swiss Wins\", \"customField0\":\"Player ID\", \"customField1\":\"Discord ID\", \"customField2\":\"Twitter ID\"})\n",
    "\n",
    "## Data Cleaning - Player ID\n",
    "df[\"Player ID\"] = df[\"Player ID\"].apply(lambda x: x.replace(\"-\", \"\").replace(\" \", \"\") )\n",
    "    ## Manual adjustments\n",
    "# df.replace('534186335', '534186334', inplace = True)\n",
    "# df.replace('24241352', '242417352', inplace = True)\n",
    "df[\"Player ID\"] = df[\"Player ID\"].apply(lambda x: int(x.replace(\" \", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4dcf036-295c-40ff-a0bf-5b9fe5d6ee71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Join tables from excel decklist to participants in battlefy\n",
    "df_comb_final = pd.concat([rawdf_1.set_index('Player ID'), df.set_index('Player ID')], axis=1, join=\"inner\").reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2008c649-6642-4645-ac6f-074cda5903ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Players extracted from SVO rawdf_1 : 201\n",
      "Players extracted from Battlefy : 175\n",
      "Players in df_comb_final : 174\n"
     ]
    }
   ],
   "source": [
    "## Check\n",
    "print(f\"Players extracted from SVO rawdf_1 : {rawdf_1.shape[0]}\")\n",
    "print(f\"Players extracted from Battlefy : {df.shape[0]}\")\n",
    "print(f\"Players in df_comb_final : {df_comb_final.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addcd932-9956-4f81-bd51-127f50fe8e53",
   "metadata": {},
   "source": [
    "## Deck Classification & Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b17c16a-2e02-4886-8cd9-5c7a0e195706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Pre-game only, otherwise keep commented\n",
    "# ## First sort the classes (use sorted which return a value, do not use sort). Then create columns for decks.\n",
    "# rawdf_1['ListOfDecks'] = rawdf_1.apply(lambda x: sorted([x['Deck 1'], x['Deck 2'], x['Deck 3']]), axis = 1)\n",
    "# for n in range(3):\n",
    "#     rawdf_1[f\"Deck{n+1}_URL\"] = rawdf_1[\"ListOfDecks\"].apply(lambda x: x[n])\n",
    "\n",
    "# ## Keep only relevant columns for subsequent use.\n",
    "# svo_dfwide = rawdf_1.copy()\n",
    "\n",
    "## First sort the classes (use sorted which return a value, do not use sort). Then create columns for decks.\n",
    "df_comb_final['ListOfDecks'] = df_comb_final.apply(lambda x: sorted([x['Deck 1'], x['Deck 2'], x['Deck 3']]), axis = 1)\n",
    "for n in range(3):\n",
    "    df_comb_final[f\"Deck{n+1}_URL\"] = df_comb_final[\"ListOfDecks\"].apply(lambda x: x[n])\n",
    "\n",
    "## Keep only relevant columns for subsequent use.\n",
    "svo_dfwide = df_comb_final.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a10e2b4-9c3d-49e3-941e-373a237b2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare wide format\n",
    "## 1. Replace card hash with card names\n",
    "for n in range(1, 4):\n",
    "    svo_dfwide[f\"Deck{n}\"] = svo_dfwide[f\"Deck{n}_URL\"].replace(cardhash_dict, regex=True)\n",
    "## 2. Pass function to classify decks    \n",
    "for n in range(1, 4):\n",
    "    svo_dfwide[f\"Deck{n}\"] = svo_dfwide[f\"Deck{n}\"].apply(lambda d: DeckSearch(d))\n",
    "## 3. Create a new column containing the lineups. To convert to tuple for immutability for sorting later.\n",
    "svo_dfwide[\"Lineup\"] = svo_dfwide.apply(lambda x: tuple([x[\"Deck1\"], x[\"Deck2\"], x[\"Deck3\"]]), axis=1)\n",
    "svo_dfwide[\"C_Lineup\"] = svo_dfwide.apply(lambda x: tuple([x[\"Deck1\"].split(\" \")[-1].title() + \"craft\", x[\"Deck2\"].split(\" \")[-1].title() + \"craft\", x[\"Deck3\"].split(\" \")[-1].title() + \"craft\"]), axis=1)\n",
    "## 4. Sort & Prepare wide format (Wide)\n",
    "svo_dfwide = svo_dfwide[['Name', 'Player ID', 'Deck1_URL', 'Deck2_URL', 'Deck3_URL', 'Deck1', 'Deck2', 'Deck3', 'Lineup', 'C_Lineup', 'Swiss Wins']]\n",
    "svo_dfwide = svo_dfwide.sort_values(['Swiss Wins', 'C_Lineup', 'Lineup', 'Name'], ascending=[False, True, True, True]).reset_index(drop = True)\n",
    "\n",
    "## Prepare columnar format (Tall)\n",
    "## 1. Stack vertically using concat, prepare two copies with renamed columns. Ignore index on appending.\n",
    "svo_dftall = pd.concat([svo_dfwide[[\"Player ID\", \"Name\", \"Deck1_URL\", \"Deck1\"]].copy().rename(columns = {\"Deck1_URL\":\"Deck_URL\", \"Deck1\":\"Deck\"}), \n",
    "                        svo_dfwide[[\"Player ID\", \"Name\", \"Deck2_URL\", \"Deck2\"]].copy().rename(columns = {\"Deck2_URL\":\"Deck_URL\", \"Deck2\":\"Deck\"}),\n",
    "                        svo_dfwide[[\"Player ID\", \"Name\", \"Deck3_URL\", \"Deck3\"]].copy().rename(columns = {\"Deck3_URL\":\"Deck_URL\", \"Deck3\":\"Deck\"})], ignore_index=True)\n",
    "## 2. Create a column for classes using string slicing.\n",
    "svo_dftall[\"Class\"] = svo_dftall[\"Deck\"].apply(lambda x: x.split(\" \")[-1].title() + \"craft\")\n",
    "## 3. Sort\n",
    "svo_dftall = svo_dftall.sort_values([\"Player ID\", \"Deck_URL\", \"Deck\"], ascending=[True, True, True]).reset_index(drop = True)\n",
    "svo_dftall['Name'] = svo_dftall['Name'].astype(str) \n",
    "\n",
    "## Create Summary DataFrame\n",
    "## Deck Summary\n",
    "deck_summary_df = svo_dftall[[\"Deck\", \"Class\"]].value_counts().reset_index(name='Count')\n",
    "deck_summary_df[\"%ofPlayers\"] = deck_summary_df[\"Count\"]/(deck_summary_df[\"Count\"].sum()/3)\n",
    "## Class Summary\n",
    "class_summary_df = svo_dftall[[\"Class\"]].value_counts().reset_index(name='Count')\n",
    "class_summary_df[\"%ofPlayers\"] = class_summary_df[\"Count\"]/(class_summary_df[\"Count\"].sum()/3)\n",
    "## Lineup Summary\n",
    "lineup_summary_df = svo_dfwide[[\"Lineup\"]].value_counts().reset_index(name='Count')\n",
    "lineup_summary_df[\"%ofPlayers\"] = lineup_summary_df[\"Count\"]/(lineup_summary_df[\"Count\"].sum())\n",
    "## C_Lineup Summary\n",
    "clineup_summary_df = svo_dfwide[[\"C_Lineup\"]].value_counts().reset_index(name='Count')\n",
    "clineup_summary_df[\"%ofPlayers\"] = clineup_summary_df[\"Count\"]/(clineup_summary_df[\"Count\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb6f3f3-ab7a-431f-a51b-73675b27d0b4",
   "metadata": {},
   "source": [
    "## Deck Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79dc00dd-7791-4407-820d-dc2e107338bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deck Breakdown. Loop through columnar format for each decks in each classes, then store all DataFrames in a dictionary.\n",
    "deck_breakdown_dict = {}\n",
    "for classes in svo_dftall[\"Class\"].unique():\n",
    "    deck_breakdown_dict[f\"{classes}\"] = {}\n",
    "    for deck in sorted(svo_dftall.loc[svo_dftall[\"Class\"] == classes][\"Deck\"].unique()):\n",
    "        # 1. Create a view of all players with the same deck archetype.\n",
    "        player_df = svo_dftall.loc[svo_dftall[\"Deck\"] == deck].copy().sort_values(by=[\"Name\"])\n",
    "        # 2. For each player, convert Deck_URL to a list of cards in the deck. \n",
    "        player_df[\"Deck_URL\"] = player_df[\"Deck_URL\"].apply(lambda x: x.split(\"deck/\")[-1].split(\"?lang\")[0][4:])\n",
    "        player_df[\"Cards\"] = player_df[\"Deck_URL\"].apply(lambda x: x.split(\".\"))\n",
    "        player_df[\"Cards\"] = player_df[\"Cards\"].apply(lambda x: [each.replace(each, cardhash_dict[each]) for each in x])\n",
    "        # 3. Convert list of cards into a DataFrame. Aggregate the Count of each cards with value_counts. Set index header as deck archetype name (which is card name too). Player forms the columns.\n",
    "        player_df[\"Cards\"] = player_df.apply(lambda x: pd.DataFrame(x[\"Cards\"], columns = [f\"{deck}\"]).value_counts().to_frame(name = x[\"Name\"]), axis=1)\n",
    "        # 4. Create a merged DataFrame, displaying the granular breakdown of all players and their ratio of cards.\n",
    "        player_list = player_df[\"Cards\"].to_list()\n",
    "        mergeddf = pd.concat(player_list, axis=1)\n",
    "        # 5. Create a separate DataFrame storing all the descriptive stats.\n",
    "        mergeddf2 = pd.DataFrame()\n",
    "        mergeddf2[\"Count\"] = mergeddf.apply(lambda x: x.count(), axis = 1)\n",
    "        mergeddf2[\"Mean\"] = mergeddf.apply(lambda x: x.mean(), axis = 1)\n",
    "        mergeddf2[\"Median\"] = mergeddf.apply(lambda x: x.median(), axis = 1)\n",
    "        mergeddf2[\"SD\"] = mergeddf.apply(lambda x: x.std(), axis = 1)\n",
    "        # 6. Merge descriptive stats DataFrame to the front, with granular DataFrame. Then append to dictionary container\n",
    "        mergeddf3 = pd.concat([mergeddf2, mergeddf], axis=1).sort_values(by=['Count', f\"{deck}\"], ascending=[False, True])\n",
    "        deck_breakdown_dict[f\"{classes}\"][f\"{deck}\"] = (mergeddf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82df67b9-202c-4015-9733-dc8cf33ec6fe",
   "metadata": {},
   "source": [
    "## Swiss Decay\n",
    "- The objective of this section is to track what players fought against, and at which point did they get X-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "100adde7-f6bd-44b7-959b-2a5c655b9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pull from battlefy and check against participating players\n",
    "targetRound = f'https://dtmwra1jsgyb0.cloudfront.net/stages/{bfyTourCode}/matches'\n",
    "jsonResponse_1 = requests.get(targetRound).json()\n",
    "df_1 = pd.json_normalize(jsonResponse_1)\n",
    "\n",
    "## Keep relevant rows for df_1, remove BYES and AFK rounds\n",
    "df_1 = df_1[(df_1['isBye'] == False) & ~(df_1['isDoubleLoss'] == True)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42c340b1-db4d-483e-ba65-07de1bb788ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extract customFields\n",
    "## Sort customFields list of dictionary by unique _id for each customFields.\n",
    "for p in ['top', 'bottom']:\n",
    "    df_1[f'{p}.team.customFields'] = df_1[f'{p}.team.customFields'].apply(lambda x: sorted(x, key = lambda y: y['_id']))\n",
    "    ## Check for the number of dictionary in list before running, adjust range(0, n) accordingly.\n",
    "    for n in range(0,3): \n",
    "        df_1[f'{p}.team.customField{n}'] = df_1[f'{p}.team.customFields'].apply(lambda x: x[n]['value'])\n",
    "\n",
    "        \n",
    "## Assume that customFields0 contains player's Shadowverse ID, else please adjust accordingly\n",
    "df_1 = df_1.rename(columns = {\"top.team.customField0\":\"top.team.sv_ID\", \"bottom.team.customField0\":\"bottom.team.sv_ID\"})\n",
    "## Data Cleaning - Player ID\n",
    "df_1[\"top.team.sv_ID\"] = df_1[\"top.team.sv_ID\"].apply(lambda x: x.replace(\"-\", \"\").replace(\" \", \"\") )\n",
    "df_1[\"bottom.team.sv_ID\"] = df_1[\"bottom.team.sv_ID\"].apply(lambda x: x.replace(\"-\", \"\").replace(\" \", \"\") )\n",
    "    ## Manual adjustments\n",
    "df_1.replace('534186335', '534186334', inplace = True)\n",
    "df_1.replace('24241352', '242417352', inplace = True)\n",
    "\n",
    "## Retain relevant information for decay\n",
    "df_2 = df_1.copy()[['roundNumber', 'isBye', 'top.team.sv_ID', 'bottom.team.sv_ID', 'top.winner', 'bottom.winner', 'top.score', 'bottom.score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f30f021a-025d-4b4e-94a0-e363f85dfce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_list = {}\n",
    "for n in range(df_2.shape[0]):\n",
    "    if df_2['top.team.sv_ID'][n] not in decay_list.keys() and df_2['top.team.sv_ID'][n] != '':\n",
    "        decay_list[df_2['top.team.sv_ID'][n]] = {'R1': '',\n",
    "                                                 'R2': '',\n",
    "                                                 'R3': '',\n",
    "                                                 'R4': '',\n",
    "                                                 'R5': '',\n",
    "                                                 'R6': '',\n",
    "                                                 'R7': '',\n",
    "                                                 'outRound': 0,\n",
    "                                                 'Xrounds': [],\n",
    "                                                 'Xcount': 0}\n",
    "        \n",
    "    if df_2['bottom.team.sv_ID'][n] not in decay_list.keys() and df_2['bottom.team.sv_ID'][n] != '':\n",
    "        decay_list[df_2['bottom.team.sv_ID'][n]] = {'R1': '',\n",
    "                                                    'R2': '',\n",
    "                                                    'R3': '',\n",
    "                                                    'R4': '',\n",
    "                                                    'R5': '',\n",
    "                                                    'R6': '',\n",
    "                                                    'R7': '',\n",
    "                                                    'outRound': 0,\n",
    "                                                    'Xrounds': [],\n",
    "                                                    'Xcount': 0}\n",
    "        \n",
    "    if df_2['isBye'][n] == False:\n",
    "        decay_list[df_2['top.team.sv_ID'][n]]['R{}'.format(df_2['roundNumber'][n])] = df_2['bottom.team.sv_ID'][n]\n",
    "        decay_list[df_2['bottom.team.sv_ID'][n]]['R{}'.format(df_2['roundNumber'][n])] = df_2['top.team.sv_ID'][n]\n",
    "        if df_2['top.winner'][n] == False:\n",
    "            decay_list[df_2['top.team.sv_ID'][n]]['Xcount'] += 1\n",
    "            decay_list[df_2['top.team.sv_ID'][n]]['Xrounds'].append(df_2['roundNumber'][n])\n",
    "            if decay_list[df_2['top.team.sv_ID'][n]]['Xcount'] == 2:\n",
    "                decay_list[df_2['top.team.sv_ID'][n]]['outRound'] = df_2['roundNumber'][n]\n",
    "        if df_2['bottom.winner'][n] == False:\n",
    "            decay_list[df_2['bottom.team.sv_ID'][n]]['Xcount'] += 1\n",
    "            decay_list[df_2['bottom.team.sv_ID'][n]]['Xrounds'].append(df_2['roundNumber'][n])\n",
    "            if decay_list[df_2['bottom.team.sv_ID'][n]]['Xcount'] == 2:\n",
    "                decay_list[df_2['bottom.team.sv_ID'][n]]['outRound'] = df_2['roundNumber'][n]\n",
    "        \n",
    "    if df_2['isBye'][n] == True:\n",
    "        decay_list[df_2['top.team.sv_ID'][n]]['R{}'.format(df_2['roundNumber'][n])] = 'BYE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64c9cf5-25b4-4841-ad9c-25368adad337",
   "metadata": {},
   "outputs": [],
   "source": [
    "svo_dfwide_temp = svo_dfwide.copy()\n",
    "svo_dfwide_temp[\"Player ID\"] = svo_dfwide_temp[\"Player ID\"].apply(lambda x: str(x))\n",
    "player_name_dict = svo_dfwide_temp.set_index(\"Player ID\")[\"Name\"].to_dict()\n",
    "player_lu_dict = svo_dfwide_temp.set_index(\"Player ID\")[\"Lineup\"].to_dict()\n",
    "player_clu_dict = svo_dfwide_temp.set_index(\"Player ID\")[\"C_Lineup\"].to_dict()\n",
    "\n",
    "## Decay by player\n",
    "df_3 = pd.DataFrame.from_dict(decay_list).T\n",
    "df_3['Name'] = df_3.index\n",
    "df_3 = df_3.replace(player_name_dict, regex = True)\n",
    "df_3 = df_3.copy().reset_index(drop = False).rename(columns = {'index': 'Player ID'})[['Player ID', 'Name', 'outRound', 'Xcount', 'Xrounds', 'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7']]\n",
    "df_3[\"Player ID\"] = df_3[\"Player ID\"].apply(lambda x: int(x))\n",
    "df_3 = pd.concat([df_3.set_index('Player ID'), df_comb_final.set_index('Player ID')['Swiss Wins']], axis=1, join=\"inner\").reset_index(drop = False)[['Player ID', 'Name', 'Swiss Wins', 'outRound', 'Xcount', 'Xrounds', 'R1', 'R2', 'R3',\n",
    "       'R4', 'R5', 'R6', 'R7']]\n",
    "df_3 = df_3.sort_values(['Swiss Wins', 'outRound', 'Xcount', 'Name'], ascending=[False, False, False, True]).reset_index(drop = True)\n",
    "\n",
    "## Decay by lineup\n",
    "df_4 = pd.DataFrame.from_dict(decay_list).T\n",
    "df_4['Name'] = df_4.index\n",
    "df_4['Name'] = df_4['Name'].replace(player_name_dict, regex = True)\n",
    "df_4['Lineup'] = df_4.index\n",
    "df_4 = df_4.replace(player_lu_dict, regex = True)\n",
    "df_4 = df_4.copy().reset_index(drop = False).rename(columns = {'index': 'Player ID'})[['Player ID', 'Name', 'outRound', 'Xcount', 'Xrounds','Lineup', 'R1', 'R2', 'R3', 'R4', 'R5', 'R6', 'R7']]\n",
    "df_4[\"Player ID\"] = df_4[\"Player ID\"].apply(lambda x: int(x))\n",
    "df_4 = pd.concat([df_4.set_index('Player ID'), df_comb_final.set_index('Player ID')['Swiss Wins']], axis=1, join=\"inner\").reset_index(drop = False)[['Player ID', 'Name', 'Swiss Wins', 'outRound', 'Xcount', 'Xrounds', 'Lineup', 'R1', 'R2', 'R3',\n",
    "       'R4', 'R5', 'R6', 'R7']]\n",
    "df_4 = df_4.sort_values(['Swiss Wins', 'outRound', 'Xcount', 'Lineup', 'Name'], ascending=[False, False, False, True, True]).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ab92f-1b59-4478-b21d-8560b4e53c0d",
   "metadata": {},
   "source": [
    "## Matchup Analysis\n",
    "- The objective of this section is to summarize and look at the matchups between lineups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f42cd724-e361-4e43-a700-6f7b968c61c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep relevant columns for df\n",
    "df_5 = df_2.copy()[['top.team.sv_ID', 'top.winner', 'top.score', 'bottom.team.sv_ID', 'bottom.winner', 'bottom.score']]\n",
    "df_5.rename(columns = {'top.team.sv_ID': 'P1', 'top.winner': 'P1_Win', 'top.score': 'P1_Games', \n",
    "                      'bottom.team.sv_ID': 'P2', 'bottom.winner': 'P2_Win', 'bottom.score': 'P2_Games'}, inplace=True)\n",
    "\n",
    "## Replace SVID with Lineup\n",
    "bkt_merged_df_a = df_5.copy()\n",
    "bkt_merged_df_a['P1'] = bkt_merged_df_a['P1'].replace(player_lu_dict, regex=True).astype(str)\n",
    "bkt_merged_df_a['P2'] = bkt_merged_df_a['P2'].replace(player_lu_dict, regex=True).astype(str)\n",
    "\n",
    "# # ## Pick only relevant columns\n",
    "bkt_merged_df_b = bkt_merged_df_a[['P1', 'P1_Win', 'P1_Games', 'P2', 'P2_Win', 'P2_Games']].sort_values(['P1', 'P2'], ascending = [True, True]).reset_index(drop = True).copy()\n",
    "bkt_merged_df_b['P1'] = bkt_merged_df_b['P1'].astype(str)\n",
    "bkt_merged_df_b['P2'] = bkt_merged_df_b['P2'].astype(str)\n",
    "# ## Sort across P1 and P2 lineups\n",
    "bkt_merged_df_b['sortcheck'] = bkt_merged_df_b.apply(lambda x: 0 if sorted([x['P1'], x['P2']]) == ([x['P1'], x['P2']]) else 1, axis = 1)\n",
    "bkt_merged_df_b[['P1', 'P2', 'P1_Win', 'P2_Win', 'P1_Games', 'P2_Games']] = bkt_merged_df_b[['P2', 'P1', 'P2_Win', 'P1_Win', 'P2_Games', 'P1_Games']].where(bkt_merged_df_b['sortcheck'] == 1, bkt_merged_df_b[['P1', 'P2', 'P1_Win', 'P2_Win', 'P1_Games', 'P2_Games']].values)\n",
    "bkt_merged_df_b.drop(['sortcheck'], axis = 1, inplace = True)\n",
    "# ## Aggregate\n",
    "bkt_merged_df_c = bkt_merged_df_b.groupby(['P1','P2']).sum().copy()\n",
    "bkt_merged_df_c['Count'] = bkt_merged_df_c['P1_Win'] + bkt_merged_df_c['P2_Win']\n",
    "bkt_merged_df_c['Spread'] = bkt_merged_df_c.apply(lambda x: abs((x['P1_Win']-x['P2_Win'])/x['Count']) , axis = 1)\n",
    "bkt_merged_df_c = bkt_merged_df_c.sort_values(['Count', 'Spread'], ascending = [False, False]).reset_index(drop = False)\n",
    "\n",
    "## Replace nicename with c_Lineup\n",
    "bkt_merged_df_i = df_5.copy()\n",
    "bkt_merged_df_i['P1'] = bkt_merged_df_i['P1'].replace(player_clu_dict, regex=True).astype(str)\n",
    "bkt_merged_df_i['P2'] = bkt_merged_df_i['P2'].replace(player_clu_dict, regex=True).astype(str)\n",
    "\n",
    "## Calculate and aggregate\n",
    "bkt_merged_df_j = bkt_merged_df_i[['P1', 'P1_Win', 'P1_Games', 'P2', 'P2_Win', 'P2_Games']].sort_values(['P1', 'P2'], ascending = [True, True]).reset_index(drop = True).copy()\n",
    "bkt_merged_df_j['P1'] = bkt_merged_df_j['P1'].astype(str)\n",
    "bkt_merged_df_j['P2'] = bkt_merged_df_j['P2'].astype(str)\n",
    "## Sort across P1 and P2 lineups\n",
    "bkt_merged_df_j['sortcheck'] = bkt_merged_df_j.apply(lambda x: 0 if sorted([x['P1'], x['P2']]) == ([x['P1'], x['P2']]) else 1, axis = 1)\n",
    "bkt_merged_df_j[['P1', 'P2', 'P1_Win', 'P2_Win', 'P1_Games', 'P2_Games']] = bkt_merged_df_j[['P2', 'P1', 'P2_Win', 'P1_Win', 'P2_Games', 'P1_Games']].where(bkt_merged_df_j['sortcheck'] == 1, bkt_merged_df_j[['P1', 'P2', 'P1_Win', 'P2_Win', 'P1_Games', 'P2_Games']].values)\n",
    "bkt_merged_df_j.drop(['sortcheck'], axis = 1, inplace = True)\n",
    "## Aggregate\n",
    "bkt_merged_df_k = bkt_merged_df_j.groupby(['P1','P2']).sum().copy()\n",
    "bkt_merged_df_k['Count'] = bkt_merged_df_k['P1_Win'] + bkt_merged_df_k['P2_Win']\n",
    "bkt_merged_df_k['Spread'] = bkt_merged_df_k.apply(lambda x: abs((x['P1_Win']-x['P2_Win'])/x['Count']) , axis = 1)\n",
    "bkt_merged_df_k = bkt_merged_df_k.sort_values(['Count', 'Spread'], ascending = [False, False]).reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb28fa50-b62d-4980-9790-f90ced814d52",
   "metadata": {},
   "source": [
    "## Export the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e16377-f211-447a-8786-c7b879ff3f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\winso\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\xlsxwriter\\workbook.py:339: UserWarning: Calling close() on already closed file.\n",
      "  warn(\"Calling close() on already closed file.\")\n"
     ]
    }
   ],
   "source": [
    "## Specify the file name and directory folder Output\n",
    "input_filename = 'SEAO SVO Apr2023 Final'\n",
    "export_filename = f\"Output/{input_filename.replace(' ', '_')}.xlsx\"\n",
    "svowriter = pd.ExcelWriter(export_filename)\n",
    "svoworkbook = svowriter.book\n",
    "\n",
    "## Add DataFrames to Sheets\n",
    "deck_summary_df.to_excel(svowriter, sheet_name=\"Summary\", index=False, startrow = 1, startcol = 0) ## Deck Archetype\n",
    "class_summary_df.to_excel(svowriter, sheet_name=\"Summary\", index=False, startrow = deck_summary_df.shape[0] + 3, startcol = 1) ## Class Summary, To be placed below Deck Archetype Table\n",
    "lineup_summary_df.to_excel(svowriter, sheet_name=\"Summary\", index=False, startrow = 1, startcol = 5) ## Lineup Statistics\n",
    "clineup_summary_df.to_excel(svowriter, sheet_name=\"Summary\", index=False, startrow = 1, startcol = 9) ## C_Lineup Statistics\n",
    "svo_dfwide.to_excel(svowriter, sheet_name='Wide', index=False) ## Wide\n",
    "df_3.to_excel(svowriter, sheet_name='DecayPlayer', index = False)\n",
    "df_4.to_excel(svowriter, sheet_name='DecayLU', index = False)\n",
    "bkt_merged_df_c.to_excel(svowriter, sheet_name='Matchup', index=False, startrow = 1, startcol = 0) ## Matchup\n",
    "bkt_merged_df_k.to_excel(svowriter, sheet_name='Matchup', index=False, startrow = 1, startcol = 9) ## Matchup\n",
    "DeckBreakdownToExcel(deck_breakdown_dict, svowriter, svoworkbook)\n",
    "svo_dftall.to_excel(svowriter, sheet_name='Tall', index=False) ## Tall\n",
    "df_comb_final[['Player ID', 'Name', 'Discord ID', 'Twitter ID', 'team.customFields']].to_excel(svowriter, sheet_name='BattlefyDB', index=False) ## battlefy\n",
    "\n",
    "## Run the Export functions for fomatting.\n",
    "SVOExcelFormatter(svowriter, svoworkbook, input_filename, df_5)\n",
    "## Save to Excel file\n",
    "svowriter.save()\n",
    "svowriter.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
